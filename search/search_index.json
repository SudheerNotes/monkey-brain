{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-monkey-brain","title":"Welcome to Monkey Brain","text":"<p>It's unusual to call this website as a <code>MonkeyBrain</code> considering the fact that a human is actually writing this content. </p> <p>Jokes aside, its a repository of all my learnings documented and structured in a way that I can retrieve easily to reduce cognitive load on my mind.</p>"},{"location":"#main-topics","title":"Main Topics:","text":"<ul> <li>Python</li> <li>Deep Learning</li> <li>Mathematics &amp; Statistics concepts</li> </ul>"},{"location":"Maths/formulas-functions/","title":"Formulas &amp; Functions","text":""},{"location":"Maths/formulas-functions/#what-is-a-sigmoid-function","title":"What is a Sigmoid function","text":"<p>The\u00a0<code>sigmoid</code>  function always outputs a number between 0 and 1. Below code snippet is a python implementation of <code>Sigmoid</code> function</p> <pre><code>def sigmoid(x): \nreturn 1/(1+torch.exp(-x))\n</code></pre>"},{"location":"Maths/formulas-functions/#what-is-l1-l2-norm","title":"What is L1 &amp; L2 Norm","text":""},{"location":"Maths/formulas-functions/#l1-norm","title":"L1 norm","text":"<p>Take the mean of the absolute value of differences (absolute value is the function that replaces negative values with positive values). This is called the mean absolute difference or L1 norm</p> <pre><code>(preds - actuals).abs().mean()\n</code></pre>"},{"location":"Maths/formulas-functions/#l2-norm","title":"L2 norm","text":"<p>Take the mean of the square of differences (which makes everything positive) and then take the square root (which undoes the squaring). This is called the root mean squared error (RMSE) or L2 norm.</p> <pre><code>(preds - actuals).sqr().mean().sqrt()\n</code></pre>"},{"location":"Maths/softmax-Cross-Entropy%20/","title":"Loss Functions","text":""},{"location":"Maths/softmax-Cross-Entropy%20/#softmax","title":"Softmax","text":"<p><code>Softmax</code> is a function that converts predicted values into probabilities for multiple classification problems.</p> <p><pre><code>def softmax(x):\nreturn torch.exp(x) / torch.exp(x).sum(dim=1,keepdim=True)\n# dim=1 ==&gt; will help us with taking Sum along columns (0 = sum along rows)\n# keepdim=True ==&gt;  this will retain dimensions hence we can run calculations\n</code></pre> Let's assume these are our predictions <pre><code>act = torch.randn((6,2))*2\nact \n==============result=================\ntensor([[-0.0758,  0.7714],\n[-0.5243, -0.7601],\n[ 1.1320, -1.8671],\n[ 1.2885,  3.6635],\n[-1.6853, -1.4489],\n[ 0.1385,  3.2162]])\n</code></pre></p> <p>These are our results after running through <code>softmax</code> function</p> <pre><code>sm_act  = softmax(act)\nsm_act\n==============result==================\ntensor([[0.3000, 0.7000],\n[0.5587, 0.4413],\n[0.9525, 0.0475],\n[0.0851, 0.9149],\n[0.4412, 0.5588],\n[0.0440, 0.9560]])\n# If we sum along columns then totals will add up to 1\n</code></pre>"},{"location":"Maths/softmax-Cross-Entropy%20/#negative-log-likelyhood-nll","title":"Negative Log Likelyhood (NLL)","text":"<p>Step1 : Take a log of Softmax results (ignore this step for now). This will allow us to expand probabilities to infinite. </p> <p>Step2 : Compare these results with actuals (targets) and pick the value that our model has predicted (i.e. if our first prediction should be 1 then select probability of 1 even if our model predicted incorrectly (i.e. higher probability for 0 ) )</p> <p>Assume these are our targets:</p> <pre><code>targ = torch.tensor([0,1,0,1,1,0])\nsm_act  = softmax(act)\nsm_act\n==============results================\ntensor([[0.3000, 0.7000],\n[0.5587, 0.4413],\n[0.9525, 0.0475],\n[0.0851, 0.9149],\n[0.4412, 0.5588],\n[0.0440, 0.9560]])\nsm_act[range(6),targ] # Index slicing \n==============results================\ntensor([0.3000, 0.4413, 0.9525, 0.9149, 0.5588, 0.0440]) # refer below table\n</code></pre>"},{"location":"Python/python-tips/","title":"This is a python tips page","text":""},{"location":"Python/python-tips/#opening-files-in-python-with-os-library","title":"Opening files in Python with OS Library","text":"<pre><code>import os\n# reading data\nwith open('data.txt', 'r') as f:\ndata = f.read()\n# writing data\nwith open('data.txt', 'w') as f:\ndata = 'some data to be written to the file'\nf.write(data)\n# list of all the files in a directory\nos.listdir('my_directory/')\n</code></pre>"},{"location":"Python/python-tips/#list-comprehension-with-if-else-condition","title":"List comprehension with IF ELSE condition","text":"<pre><code># Only IF\n[i*20 for i in range(1,20) if i &gt;10]\n#-------------result------------\n# [220, 240, 260, 280, 300, 320, 340, 360, 380]\n# If ELSE\n[ i*20 if i &gt;10 else i for i in range(1,20) ]\n#----------------result-----------------\n# [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 220, 240, 260, 280, 300, 320, 340, 360, 380]\n</code></pre>"},{"location":"Tools/my_software_tools/","title":"My Software tools","text":""},{"location":"Tools/my_software_tools/#command-line-tools","title":"Command line tools","text":"<ul> <li><code>btop</code> - Terminal process monitor for Linux systems - link</li> <li><code>nvtop</code> - Terminal GPU process monitor for Linux systems - link</li> <li><code>tldr</code> - Simple Terminal App for quick reference docs similar to <code>man</code> - link (how to install: <code>sudo apt install tldr &amp;&amp; tldr -u</code>)</li> </ul>"},{"location":"setup-guide/fastai-setup/","title":"Install FastAI","text":"<p>Let's learn how to install FastAI in local <code>Ubuntu</code> machine, if you are using <code>WSL</code> then the instructions will be same.</p> <ul> <li> <p>Step 1 First step is to install Python using Mambaforge, its super fast compared to the other options.</p> <p>Mambaforge works interchangeably with Conda, here is a link to the Github repository, make sure to download from <code>Mambaforge</code> table.</p> </li> <li> <p>Step 2: Next go to official Pytorch website and select toggles as per your need.  In my case I've selected the below toggles.</p> <pre><code>    PyTorch Build: stable\n    Your OS: Linux\n    Package: conda - If you are into Data Science then Conda works better\n    Language: python\n    Compute Platform: 11.7 (in general most packages work better if you select one version below latest) \n</code></pre> </li> <li> <p>Step 3: Next copy suggested command as per your selections and then open your terminal and run it</p> <p><code>mamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia</code></p> <p>Make sure to replace <code>conda</code> with <code>mamba</code></p> </li> <li> <p>Step 4: Now install <code>FastAi</code> using the below command, here is a link to FastAi documentation.</p> <p><code>mamba install -c fastchan fastai</code></p> </li> <li> <p>Step 5: Instal Jupyter Notebook using the below command.</p> <p><code>mamba install -c conda-forge jupyterlab</code></p> </li> </ul>"}]}